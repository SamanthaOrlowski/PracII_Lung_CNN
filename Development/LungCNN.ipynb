{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0276a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path \n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pydicom\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1ee9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for the model\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_preprocessing.image.dataframe_iterator import DataFrameIterator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.engine import  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6b0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dicom images\n",
    "def get_dicom_dict(anno_dict, limit=0):\n",
    "    dicomFiles = os.walk('/Users/samanthasullivan/Desktop/Prac_II_Code/saved_files/manifest-1608669183333/Lung-PET-CT-Dx', topdown=False)\n",
    "    dcm_dict = {}\n",
    "    class_freq_map = {}\n",
    "    for root, dir, files in dicomFiles:\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                fullPath = os.path.join(root, file)\n",
    "                dicomInfo = pydicom.read_file(fullPath, force=True)\n",
    "                dicomFileIdentifier = dicomInfo.SOPInstanceUID;\n",
    "                #Only use Dicom images that have Class ID 1.1.7\n",
    "                if(dicomFileIdentifier in anno_dict):\n",
    "                    if(dicomInfo.SOPClassUID != '1.2.840.10008.5.1.4.1.1.7'):\n",
    "                        continue\n",
    "                    if(dicomInfo.SOPClassUID in class_freq_map):\n",
    "                        class_freq_map[dicomInfo.SOPClassUID] = class_freq_map[dicomInfo.SOPClassUID] + 1\n",
    "                    else:\n",
    "                        class_freq_map[dicomInfo.SOPClassUID] = 1\n",
    "                    dcm_dict[dicomFileIdentifier] = fullPath\n",
    "                    if(limit > 0 and len(dcm_dict) > limit):\n",
    "                        return dcm_dict\n",
    "                    if(len(dcm_dict)%1000 == 0):\n",
    "                        print(len(dcm_dict))\n",
    "                        print(class_freq_map)\n",
    "    return dcm_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cf928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get annotations\n",
    "def get_anno_dict():\n",
    "    annotation = os.walk('/Users/samanthasullivan/Desktop/Prac_II_Code/saved_files/other data/Annotation', topdown=False)\n",
    "    anno = []\n",
    "    anno_dict = {}\n",
    "    for root, dir, files in annotation:\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                try:\n",
    "                    anno_full_path = os.path.join(root, file)\n",
    "                    tree = etree.parse(anno_full_path)\n",
    "                    anno_label = tree.getroot()\n",
    "                    #Get labels of A, B, E or G and remove .xml from filepath\n",
    "                    label = anno_label.find(\"object\").find(\"name\").text\n",
    "                    anno_id = file.replace('.xml', '')\n",
    "                    anno_dict[anno_id] = label\n",
    "                #show bad file and continue    \n",
    "                except:\n",
    "                    print(\"Unexpected error!!! Bad file: \" + anno_full_path)\n",
    "                    continue\n",
    "#                if(len(anno_dict)%500 == 0):\n",
    " #                   print(len(anno_dict))\n",
    "    return anno_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error!!! Bad file: /Users/samanthasullivan/Desktop/Prac_II_Code/saved_files/other data/Annotation/A0024/1.3.6.1.4.1.14519.5.2.1.6655.2359.148117780944430339778694852523.xml\n",
      "30992\n"
     ]
    }
   ],
   "source": [
    "#Print all the annotations that met the criteria\n",
    "anno_dict = get_anno_dict()\n",
    "print(len(anno_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98df9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 1000}\n",
      "2000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 2000}\n",
      "3000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 3000}\n",
      "4000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 4000}\n",
      "5000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 5000}\n",
      "6000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 6000}\n",
      "7000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 7000}\n",
      "8000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 8000}\n",
      "9000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 9000}\n",
      "10000\n",
      "{'1.2.840.10008.5.1.4.1.1.7': 10000}\n",
      "10357\n"
     ]
    }
   ],
   "source": [
    "#Print all the Dicom images that have annotations\n",
    "dcm_dict = get_dicom_dict(anno_dict)\n",
    "print(len(dcm_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993b4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class for the Data Image Generator\n",
    "class DCMDataFrameIterator(DataFrameIterator):\n",
    "    def __init__(self, *arg, **kwargs):\n",
    "        self.white_list_formats = ('dcm')\n",
    "        super(DCMDataFrameIterator, self).__init__(*arg, **kwargs)\n",
    "        self.dataframe = kwargs['dataframe']\n",
    "        self.x = self.dataframe[kwargs['x_col']]\n",
    "        self.y = self.dataframe[kwargs['y_col']]\n",
    "        self.color_mode = kwargs['color_mode']\n",
    "        self.target_size = kwargs['target_size']\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, indices_array):\n",
    "        # get batch of images\n",
    "        print(len(self.x))\n",
    "        print(indices_array)\n",
    "        batch_x = np.array([self.read_dcm_as_array(dcm_path, self.target_size, color_mode=self.color_mode)\n",
    "                            for dcm_path in self.x.iloc[indices_array]])\n",
    "\n",
    "        batch_y = np.array(self.y.iloc[indices_array].astype(np.uint8)) \n",
    "\n",
    "        # transform the images\n",
    "        if self.image_data_generator is not None:\n",
    "            for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n",
    "                transform_params = self.image_data_generator.get_random_transform(x.shape)\n",
    "                batch_x[i] = self.image_data_generator.apply_transform(x, transform_params)\n",
    "                 \n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def read_dcm_as_array(dcm_path, target_size=(256, 256), color_mode='rgb'):\n",
    "        image_array = pydicom.dcmread(dcm_path).pixel_array\n",
    "        image_array = cv2.resize(image_array, target_size, interpolation=cv2.INTER_NEAREST) \n",
    "        image_array = np.expand_dims(image_array, -1)\n",
    "        if color_mode == 'rgb':\n",
    "            image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)\n",
    "        print(image_array.shape)\n",
    "        return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd0593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Create an array that holds the correct dcm files that have matching annotations.\n",
    "anno_labels = []\n",
    "anno_keys = []\n",
    "for key in anno_dict.keys():\n",
    "    if(key in dcm_dict):\n",
    "        anno_labels.append(anno_dict[key])\n",
    "        anno_keys.append(key)\n",
    "\n",
    "#Change the labels to int for the model and print\n",
    "anno_array = np.array(anno_labels)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(anno_array)\n",
    "anno_cat = to_categorical(encoded_labels)\n",
    "print(anno_cat)\n",
    "anno_encoded_dict = {}\n",
    "for i in range(0, len(anno_keys)):\n",
    "    anno_encoded_dict[anno_keys[i]] = anno_cat[i]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "070867a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            target  \\\n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000366410969...  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000931701564...  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000951831341...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1001825974274...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1002527447226...  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
      "...                                                                            ...   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984373152522...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984434358737...  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984573937225...  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9986379068768...  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9993480878410...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
      "\n",
      "                                                                                           image_path  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000366410969...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000931701564...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1000951831341...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1001825974274...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.1002527447226...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "...                                                                                               ...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984373152522...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984434358737...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9984573937225...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9986379068768...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "1.3.6.1.4.1.14519.5.2.1.6655.2359.9993480878410...  /Users/samanthasullivan/Desktop/Prac_II_Code/s...  \n",
      "\n",
      "[10357 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe for the cleaned and usable data\n",
    "df = pd.DataFrame({'target':pd.Series(anno_encoded_dict),'image_path':pd.Series(dcm_dict)})\n",
    "df['image_path'] = df['image_path'].astype('str') \n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38ac868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8285\n",
      "2072\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and test, train %80 test %20.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a84f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the train and test image size peramiters\n",
    "train_augmentation_parameters = dict(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "valid_augmentation_parameters = dict(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "test_augmentation_parameters = dict(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "# The training parameters for the model\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'input'\n",
    "COLOR_MODE = 'grayscale'\n",
    "TARGET_SIZE = (300, 300)\n",
    "EPOCHS = 10\n",
    "SEED = 1337\n",
    "\n",
    "train_consts = {\n",
    "    'seed': SEED,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'class_mode': CLASS_MODE,\n",
    "    'color_mode': COLOR_MODE,\n",
    "    'target_size': TARGET_SIZE,  \n",
    "    'subset': 'training'\n",
    "}\n",
    "\n",
    "valid_consts = {\n",
    "    'seed': SEED,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'class_mode': CLASS_MODE,\n",
    "    'color_mode': COLOR_MODE,\n",
    "    'target_size': TARGET_SIZE, \n",
    "    'subset': 'validation'\n",
    "}\n",
    "\n",
    "test_consts = {\n",
    "    'batch_size': 1,  #size 1 for testing\n",
    "    'class_mode': CLASS_MODE,\n",
    "    'color_mode': COLOR_MODE,\n",
    "    'target_size': TARGET_SIZE,  # resize input images\n",
    "    'shuffle': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "647c5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declair the training and validation generators\n",
    "train_augmenter = ImageDataGenerator(**train_augmentation_parameters)\n",
    "valid_augmenter = ImageDataGenerator(**valid_augmentation_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92d22635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6628 validated image filenames.\n",
      "Found 414 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#set the paramiters for the train and validate generators\n",
    "train_generator = DCMDataFrameIterator(dataframe=train_df,\n",
    "                                    x_col='image_path',\n",
    "                                    y_col='target',\n",
    "                                    image_data_generator=train_augmenter,\n",
    "                                    **train_consts)\n",
    "\n",
    "valid_generator = DCMDataFrameIterator(dataframe=test_df,\n",
    "                             x_col='image_path',\n",
    "                             y_col='target',\n",
    "                             image_data_generator=valid_augmenter,\n",
    "                             **valid_consts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc61252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,\n",
    "kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,\n",
    "kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),\n",
    "padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
    "padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=10,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63262fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 512)     590336    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6422528)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                64225290  \n",
      "=================================================================\n",
      "Total params: 65,075,786\n",
      "Trainable params: 65,075,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print summary with metrics\n",
    "model.compile(optimizer= keras.optimizers.RMSprop(lr=0.001), loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04458526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8285\n",
      "[ 820 5356 6186  543 3982 3351 4736 3143 4045 4415 5284  613 3533 3703\n",
      "  248  338 1105 4976 6011 6314 3177  197 1628  327 5774 2204 3826 4533\n",
      "  173 3960 6379 5104]\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n",
      "(300, 300, 3, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-707eb8d81b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearlyStopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-135ded6ec6e9>\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, indices_array)\u001b[0m\n\u001b[1;32m     16\u001b[0m                             for dcm_path in self.x.iloc[indices_array]])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# astype because y was passed as str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# transform images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5875\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     ) -> \"BlockManager\":\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     def convert(\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/LungNerualNetwork/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#Complete the training\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    callbacks=[earlyStopping],\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the model, Not used since model not trained\n",
    "plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics)\n",
    "    plt.plot(epochs, val_metrics)\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
